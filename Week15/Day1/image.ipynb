{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715aabfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304.72266666666667\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import httpx\n",
    "\n",
    "image_url = \"https://i.redd.it/1267kk74qmhf1.png\"\n",
    "image_media_type = \"image/png\"\n",
    "image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
    "\n",
    "dimensions = \"458 × 499\"\n",
    "\n",
    "\n",
    "estimated_tokens = (458 * 499) / 750 # Source: https://docs.anthropic.com/en/docs/build-with-claude/vision\n",
    "\n",
    "print(estimated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff25502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message(id='msg_01NrLYS25poKodkmgg9ofJsc', content=[TextBlock(citations=None, text='This image shows a bar chart titled \"Academic\" that presents performance data for software engineering problems from the SWE-bench Verified dataset. The chart compares accuracy scores (as percentages on the y-axis) across three different AI models:\\n\\n1. **GPT-5**: Shows the highest performance with 74.9% accuracy, with the bar divided into two sections - \"Without thinking\" (52.8%) and \"With thinking\" (an additional portion that brings the total to 74.9%)\\n\\n2. **OpenAI o3**: Achieves 69.1% accuracy (shown as a light-colored bar)\\n\\n3. **GPT-4o**: Has the lowest performance at 30.8% accuracy (also shown as a light-colored bar)\\n\\nThe chart uses a pink/magenta color scheme to distinguish between different thinking approaches for GPT-5, while the other models are shown in lighter colors. This appears to be measuring how well these AI models can solve software engineering problems, with GPT-5 demonstrating significantly better performance, especially when using some form of enhanced reasoning approach.', type='text')], model='claude-sonnet-4-20250514', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=322, output_tokens=241, server_tool_use=None, service_tier='standard'))\n",
      "Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=322, output_tokens=241, server_tool_use=None, service_tier='standard')\n",
      "322\n",
      "241\n",
      "====\n",
      "This image shows a bar chart titled \"Academic\" that presents performance data for software engineering problems from the SWE-bench Verified dataset. The chart compares accuracy scores (as percentages on the y-axis) across three different AI models:\n",
      "\n",
      "1. **GPT-5**: Shows the highest performance with 74.9% accuracy, with the bar divided into two sections - \"Without thinking\" (52.8%) and \"With thinking\" (an additional portion that brings the total to 74.9%)\n",
      "\n",
      "2. **OpenAI o3**: Achieves 69.1% accuracy (shown as a light-colored bar)\n",
      "\n",
      "3. **GPT-4o**: Has the lowest performance at 30.8% accuracy (also shown as a light-colored bar)\n",
      "\n",
      "The chart uses a pink/magenta color scheme to distinguish between different thinking approaches for GPT-5, while the other models are shown in lighter colors. This appears to be measuring how well these AI models can solve software engineering problems, with GPT-5 demonstrating significantly better performance, especially when using some form of enhanced reasoning approach.\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": image_media_type,\n",
    "                        \"data\": image_data,\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Describe this image.\"\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(message)\n",
    "print(message.usage)\n",
    "print(message.usage.input_tokens)\n",
    "print(message.usage.output_tokens)\n",
    "print(\"====\")\n",
    "print(message.content[0].text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
