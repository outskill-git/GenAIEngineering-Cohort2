{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Import phidata\n",
    "Install the phidata library and import necessary modules for working with agents, tools, knowledge, and storage components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy==1.26.4 ipykernel phidata openai ipywidgets duckduckgo-search yfinance crawl4ai lancedb sentence-transformers torch pypdf chromadb duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation of the Code\n",
    "\n",
    "The code performs the following steps:\n",
    "\n",
    "1. **Importing Required Modules**:\n",
    "    - `os`: Provides functions to interact with the operating system.\n",
    "    - `load_dotenv` from `dotenv`: Loads environment variables from a `.env` file into the system environment.\n",
    "\n",
    "2. **Loading Environment Variables**:\n",
    "    - The `load_dotenv()` function is called to load environment variables from a `.env` file.\n",
    "\n",
    "3. **Clearing Conflicting Environment Variables**:\n",
    "    - A list of environment variables (`env_vars_to_clear`) is defined, which includes `OPENAI_API_KEY`, `OPENAI_BASE_URL`, and `OPENAI_API_BASE`.\n",
    "    - For each variable in the list, the code checks if it exists in the environment. If it does, it prints a warning message and deletes the variable from the environment.\n",
    "\n",
    "4. **Setting New Environment Variables**:\n",
    "    - The `OPENAI_API_KEY` is set to the value of the `OPEN_ROUTER_KEY` environment variable.\n",
    "    - Both `OPENAI_API_BASE` and `OPENAI_BASE_URL` are set to `'https://openrouter.ai/api/v1'`.\n",
    "\n",
    "5. **Commented-Out Code**:\n",
    "    - There is an alternative block of code (commented out) that clears the same environment variables and sets `OPENAI_API_KEY` to the value of the `OPEN_AI_KEY` environment variable instead.\n",
    "\n",
    "### Purpose:\n",
    "This code ensures that conflicting environment variables are removed and sets up the required environment variables for interacting with the OpenRouter API. It provides flexibility to switch between different API keys and base URLs by modifying the `.env` file or uncommenting the alternative block of code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "env_vars_to_clear = ['OPENAI_API_KEY', 'OPENAI_BASE_URL', 'OPENAI_API_BASE']\n",
    "for var in env_vars_to_clear:\n",
    "    if os.getenv(var):\n",
    "        print(f\"⚠️  Removing conflicting {var}\")\n",
    "        del os.environ[var]\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPEN_ROUTER_KEY\")\n",
    "os.environ['OPENAI_API_BASE'] = 'https://openrouter.ai/api/v1'\n",
    "os.environ['OPENAI_BASE_URL'] = 'https://openrouter.ai/api/v1'\n",
    "\n",
    "\n",
    "\n",
    "# env_vars_to_clear = ['OPENAI_API_KEY', 'OPENAI_BASE_URL', 'OPENAI_API_BASE']\n",
    "# for var in env_vars_to_clear:\n",
    "#     if os.getenv(var):\n",
    "#         print(f\"⚠️  Removing conflicting {var}\")\n",
    "#         del os.environ[var]\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPEN_AI_KEY\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "The code in the next cell performs the following steps:\n",
    "\n",
    "1. **Importing Required Modules**:\n",
    "    - `phi.agent.Agent`: Used to create an agent that can perform reasoning tasks.\n",
    "    - `phi.tools.Tool`: Provides tools that can be used by the agent.\n",
    "    - `phi.model.openai.OpenAIChat`: Represents the OpenAI GPT model used for generating responses.\n",
    "    - `phi.utils.pprint.pprint_run_response`: A utility function to pretty-print the agent's response.\n",
    "\n",
    "### Purpose:\n",
    "This code sets up the necessary imports to create and interact with agents that utilize OpenAI's GPT models for reasoning and task execution. It also includes tools and utilities for enhancing the agent's functionality and formatting its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phi.agent import Agent\n",
    "from phi.tools import Tool\n",
    "from phi.model.openai import OpenAIChat\n",
    "from phi.utils.pprint import pprint_run_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation of the Code\n",
    "\n",
    "The code in the next cell performs the following steps:\n",
    "\n",
    "1. **Defining the Task**:\n",
    "    - A variable `task` is defined, containing a classic river-crossing puzzle involving missionaries and cannibals. The task requires a step-by-step solution and an ASCII diagram representation.\n",
    "\n",
    "2. **Creating a Reasoning Agent**:\n",
    "    - An instance of the `Agent` class is created with the following parameters:\n",
    "        - `model`: Specifies the OpenAI GPT model (`openai/gpt-4o`) to be used.\n",
    "        - `reasoning`: Enables reasoning capabilities for the agent.\n",
    "        - `markdown`: Ensures the output is formatted in Markdown.\n",
    "        - `structured_outputs`: Enables structured outputs for better organization of the response.\n",
    "\n",
    "3. **Executing the Task**:\n",
    "    - The `print_response` method of the agent is called with the following parameters:\n",
    "        - `task`: The river-crossing puzzle defined earlier.\n",
    "        - `stream`: Enables streaming of the response.\n",
    "        - `show_full_reasoning`: Displays the full reasoning process of the agent.\n",
    "\n",
    "### Purpose:\n",
    "This code sets up a reasoning agent to solve a logical puzzle. It demonstrates the agent's ability to reason through complex problems and present the solution in a structured and Markdown-formatted manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "task = (\n",
    "    \"Three missionaries and three cannibals need to cross a river. \"\n",
    "    \"They have a boat that can carry up to two people at a time. \"\n",
    "    \"If, at any time, the cannibals outnumber the missionaries on either side of the river, the cannibals will eat the missionaries. \"\n",
    "    \"How can all six people get across the river safely? Provide a step-by-step solution and show the solutions as an ascii diagram\"\n",
    ")\n",
    "\n",
    "reasoning_agent = Agent(model=OpenAIChat(id=\"openai/gpt-4o\"), reasoning=True, markdown=True, structured_outputs=True)\n",
    "reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation of the Code\n",
    "\n",
    "The code in the next cell performs the following steps:\n",
    "\n",
    "1. **Creating a New Agent**:\n",
    "    - A variable `agent` is defined as an instance of the `Agent` class.\n",
    "    - The agent is initialized with the following parameters:\n",
    "        - `model`: Specifies the OpenAI GPT model (`gpt-4o`) to be used.\n",
    "        - `instructions`: Provides specific instructions for the agent to operate in the \"Indian context.\"\n",
    "\n",
    "2. **Running the Agent**:\n",
    "    - The `run` method of the agent is called with the input `\"Share a 2 sentence horror story\"`.\n",
    "    - The agent processes the input and generates a response.\n",
    "\n",
    "3. **Pretty-Printing the Response**:\n",
    "    - The `pprint_run_response` function is used to format and display the agent's response in Markdown format.\n",
    "\n",
    "### Purpose:\n",
    "This code demonstrates how to create and configure an agent with specific instructions, run it with a given input, and display the response in a readable format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(model=OpenAIChat(id=\"gpt-4o\"), instructions=[\"in indian context\"])\n",
    "# agent.print_response(\"Share a 2 sentence horror story\", stream=True)\n",
    "\n",
    "response=agent.run(\"Share a 2 sentence horror story\")\n",
    "# print(response)\n",
    "\n",
    "pprint_run_response(response, markdown=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation of the Code\n",
    "\n",
    "The code in the next cell performs the following steps:\n",
    "\n",
    "1. **Running the Agent with a New Input**:\n",
    "    - The `agent.run()` method is called with the input `\"Simulation theory\"`.\n",
    "    - This method processes the input and generates a response based on the agent's configuration and reasoning capabilities.\n",
    "\n",
    "2. **Streaming the Response**:\n",
    "    - The `stream=True` parameter ensures that the response is streamed in real-time as it is generated.\n",
    "\n",
    "3. **Pretty-Printing the Response**:\n",
    "    - The `pprint_run_response()` function is used to format and display the streamed response in Markdown format.\n",
    "    - The `show_time=True` parameter includes timestamps in the output, providing additional context about when each part of the response was generated.\n",
    "\n",
    "### Purpose:\n",
    "This code demonstrates how to use the agent to process a new input (`\"Simulation theory\"`) and display the response in a structured and readable format with timestamps. It highlights the agent's ability to handle dynamic inputs and provide real-time feedback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Run agent and return the response as a stream\n",
    "response_stream = agent.run(\"Simulation theory\", stream=True)\n",
    "# Print the response stream in markdown format\n",
    "pprint_run_response(response_stream, markdown=True, show_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation of the Code\n",
    "\n",
    "The code in the next cell performs the following steps:\n",
    "\n",
    "1. **Defining a Pydantic Model**:\n",
    "    - A `MovieScript` class is defined using Pydantic's `BaseModel`.\n",
    "    - This model enforces a structured format for movie scripts with the following fields:\n",
    "        - `setting`: Describes the setting of the movie.\n",
    "        - `ending`: Specifies the ending of the movie, defaulting to a happy ending if not provided.\n",
    "        - `genre`: Defines the genre of the movie, defaulting to action, thriller, or romantic comedy if not specified.\n",
    "        - `name`: Assigns a name to the movie.\n",
    "        - `characters`: Lists the names of the characters in the movie.\n",
    "        - `storyline`: Provides a 3-sentence storyline for the movie.\n",
    "\n",
    "2. **Creating Agents**:\n",
    "    - Two agents are created using the `Agent` class:\n",
    "        - `json_mode_agent`: Configured to write movie scripts with a description of \"You write movie scripts.\"\n",
    "        - `structured_output_agent`: Similar to `json_mode_agent` but intended for structured outputs (though this feature is commented out).\n",
    "\n",
    "3. **Running the Agent**:\n",
    "    - The `json_mode_agent` is instructed to generate a movie script for \"a love story\" using the `print_response` method with streaming enabled.\n",
    "\n",
    "4. **Commented-Out Code**:\n",
    "    - The `structured_output_agent` is also set up to generate a movie script for \"New York,\" but this functionality is commented out.\n",
    "\n",
    "### Purpose:\n",
    "This code demonstrates how to define a structured format for movie scripts using Pydantic and create agents capable of generating movie scripts based on specific inputs. It highlights the flexibility of the agents to work in JSON mode or structured output mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from phi.agent import Agent\n",
    "from phi.model.openai import OpenAIChat\n",
    "\n",
    "# Define a Pydantic model to enforce the structure of the output\n",
    "class MovieScript(BaseModel):\n",
    "    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n",
    "    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n",
    "    genre: str = Field(..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\")\n",
    "    name: str = Field(..., description=\"Give a name to this movie\")\n",
    "    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n",
    "    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n",
    "\n",
    "# Agent that uses JSON mode\n",
    "json_mode_agent = Agent(\n",
    "    model=OpenAIChat(id=\"openai/gpt-4o\"),\n",
    "    description=\"You write movie scripts.\",\n",
    " \n",
    ")\n",
    "json_mode_agent.print_response(\"a love story\", stream=True)\n",
    "\n",
    "\n",
    "# Agent that uses structured outputs\n",
    "# structured_output_agent = Agent(\n",
    "#     model=OpenAIChat(id=\"gpt-4o\"),\n",
    "#     description=\"You write movie scripts.\",\n",
    "#     response_model=MovieScript,\n",
    "#     structured_outputs=True,\n",
    "# )\n",
    "\n",
    "# structured_output_agent.print_response(\"New York\", stream=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from phi.agent import Agent\n",
    "# from phi.model.openai import OpenAIChat\n",
    "# from phi.storage.agent.sqlite import SqlAgentStorage\n",
    "# from phi.tools.duckduckgo import DuckDuckGo\n",
    "# from phi.tools.yfinance import YFinanceTools\n",
    "# from phi.playground import Playground, serve_playground_app\n",
    "\n",
    "# web_agent = Agent(\n",
    "#     name=\"Web Agent\",\n",
    "#     model=OpenAIChat(id=\"gpt-4o\"),\n",
    "#     tools=[DuckDuckGo()],\n",
    "#     instructions=[\"Always include sources\"],\n",
    "#     storage=SqlAgentStorage(table_name=\"web_agent\", db_file=\"agents.db\"),\n",
    "#     add_history_to_messages=True,\n",
    "#     markdown=True,\n",
    "# )\n",
    "\n",
    "# finance_agent = Agent(\n",
    "#     name=\"Finance Agent\",\n",
    "#     model=OpenAIChat(id=\"gpt-4o\"),\n",
    "#     tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],\n",
    "#     instructions=[\"Use tables to display data\"],\n",
    "#     storage=SqlAgentStorage(table_name=\"finance_agent\", db_file=\"agents.db\"),\n",
    "#     add_history_to_messages=True,\n",
    "#     markdown=True,\n",
    "# )\n",
    "\n",
    "# app = Playground(agents=[finance_agent, web_agent]).get_app()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     serve_playground_app(\"playground:app\", reload=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phidata_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
