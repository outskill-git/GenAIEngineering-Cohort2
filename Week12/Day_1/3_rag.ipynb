{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install numpy==1.26.4 ipykernel phidata openai ipywidgets duckduckgo-search yfinance crawl4ai lancedb sentence-transformers torch pypdf chromadb duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The code in the next cell performs the following actions:\n",
    "\n",
    "1. **Importing Modules**:\n",
    "    - `os`: Provides a way to interact with the operating system.\n",
    "    - `load_dotenv` from `dotenv`: Loads environment variables from a `.env` file into the system environment.\n",
    "\n",
    "2. **Loading Environment Variables**:\n",
    "    - `load_dotenv()`: Reads the `.env` file and loads the variables into the environment.\n",
    "\n",
    "3. **Clearing Conflicting Environment Variables**:\n",
    "    - A list of environment variables (`OPENAI_API_KEY`, `OPENAI_BASE_URL`, `OPENAI_API_BASE`) is defined.\n",
    "    - For each variable in the list, if it exists in the environment, it is removed to avoid conflicts. A warning message is printed for each removed variable.\n",
    "\n",
    "4. **Setting New Environment Variables**:\n",
    "    - The `OPENAI_API_KEY` environment variable is set to the value of `OPEN_AI_KEY` from the environment.\n",
    "\n",
    "This setup ensures that the environment is properly configured and free of conflicts before proceeding with further operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# env_vars_to_clear = ['OPENAI_API_KEY', 'OPENAI_BASE_URL', 'OPENAI_API_BASE']\n",
    "# for var in env_vars_to_clear:\n",
    "#     if os.getenv(var):\n",
    "#         print(f\"⚠️  Removing conflicting {var}\")\n",
    "#         del os.environ[var]\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPEN_ROUTER_KEY\")\n",
    "os.environ['OPENAI_API_BASE'] = 'https://openrouter.ai/api/v1'\n",
    "os.environ['OPENAI_BASE_URL'] = 'https://openrouter.ai/api/v1'\n",
    "\n",
    "\n",
    "\n",
    "# env_vars_to_clear = ['OPENAI_API_KEY', 'OPENAI_BASE_URL', 'OPENAI_API_BASE']\n",
    "# for var in env_vars_to_clear:\n",
    "#     if os.getenv(var):\n",
    "#         print(f\"⚠️  Removing conflicting {var}\")\n",
    "#         del os.environ[var]\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPEN_AI_KEY\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The code in the next cell performs the following actions:\n",
    "\n",
    "1. **Importing Modules**:\n",
    "    - `os`: Provides a way to interact with the operating system.\n",
    "    - `load_dotenv` from `dotenv`: Loads environment variables from a `.env` file into the system environment.\n",
    "\n",
    "2. **Loading Environment Variables**:\n",
    "    - `load_dotenv()`: Reads the `.env` file and loads the variables into the environment.\n",
    "\n",
    "3. **Clearing Conflicting Environment Variables**:\n",
    "    - A list of environment variables (`OPENAI_API_KEY`, `OPENAI_BASE_URL`, `OPENAI_API_BASE`) is defined.\n",
    "    - For each variable in the list, if it exists in the environment, it is removed to avoid conflicts. A warning message is printed for each removed variable.\n",
    "\n",
    "4. **Setting New Environment Variables**:\n",
    "    - The `OPENAI_API_KEY` environment variable is set to the value of `OPEN_AI_KEY` from the environment.\n",
    "\n",
    "This setup ensures that the environment is properly configured and free of conflicts before proceeding with further operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the phidata library and import necessary modules for working with agents, tools, knowledge, and storage components.\n",
    "\n",
    "# Install the phidata library\n",
    "# ! pip install phidata\n",
    "\n",
    "# Import necessary modules from phidata\n",
    "from phi.agent import Agent\n",
    "from phi.tools import Tool\n",
    "from phi.model.openai import OpenAIChat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "The code in the next cell performs the following actions:\n",
    "\n",
    "1. **Importing Modules**:\n",
    "    - `Agent` and `AgentKnowledge` from `phi.agent`: These are used to create an intelligent agent and manage its knowledge base.\n",
    "    - `OpenAIEmbedder` from `phi.embedder.openai`: This is used to generate embeddings for text using OpenAI's embedding models.\n",
    "    - `LanceDb` and `SearchType` from `phi.vectordb.lancedb`: These are used to manage a vector database for storing and searching embeddings.\n",
    "\n",
    "2. **Creating a Knowledge Base**:\n",
    "    - An `AgentKnowledge` object is created with a `LanceDb` vector database.\n",
    "    - The vector database is configured with:\n",
    "        - `table_name`: The name of the table in the database (`\"recipes\"`).\n",
    "        - `uri`: The location of the database (`\"tmp/lancedb\"`).\n",
    "        - `search_type`: The type of search to perform (`SearchType.vector`).\n",
    "        - `embedder`: The embedding model to use (`OpenAIEmbedder` with the model `\"text-embedding-3-small\"`).\n",
    "\n",
    "3. **Adding Information to the Knowledge Base**:\n",
    "    - A sample text (`\"The sky is green\"`) is loaded into the knowledge base.\n",
    "\n",
    "4. **Creating an Agent**:\n",
    "    - An `Agent` object is created with the knowledge base.\n",
    "    - The agent is configured to search the knowledge base when needed (`search_knowledge=True`).\n",
    "\n",
    "This setup initializes an intelligent agent with a knowledge base that can store and retrieve information using vector embeddings.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phi.agent import Agent, AgentKnowledge\n",
    "# from phi.embedder.openai import OpenAIEmbedder\n",
    "from phi.embedder.sentence_transformer import SentenceTransformerEmbedder\n",
    "from phi.vectordb.lancedb import LanceDb, SearchType\n",
    "\n",
    "# Create a knowledge base for the Agent\n",
    "knowledge_base = AgentKnowledge(vector_db=LanceDb(\n",
    "        table_name=\"custom_knowledge\",\n",
    "        uri=\"tmp/lancedb\",\n",
    "        search_type=SearchType.vector,\n",
    "        # embedder=OpenAIEmbedder(model=\"text-embedding-3-small\"))\n",
    "        embedder=SentenceTransformerEmbedder(model=\"all-MiniLM-L6-v2\" ) \n",
    "    ),)\n",
    "\n",
    "\n",
    "\n",
    "# Add information to the knowledge base\n",
    "knowledge_base.load_text(\"The sky is green\")\n",
    "\n",
    "# Add the knowledge base to the Agent and\n",
    "# give it a tool to search the knowledge base as needed\n",
    "agent = Agent(knowledge=knowledge_base, search_knowledge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The code in the next cell performs the following actions:\n",
    "\n",
    "1. **Running the Agent**:\n",
    "    - The `run` method of the `agent` object is called with the input `\"answer from the knowledge base, what is the color of sky?\"`.\n",
    "    - This prompts the agent to search its knowledge base and provide an answer based on the stored information.\n",
    "\n",
    "2. **Knowledge Base Query**:\n",
    "    - The agent uses its configured knowledge base to retrieve relevant information.\n",
    "    - In this case, the knowledge base contains the text `\"The sky is green\"`, which will be used to generate a response.\n",
    "\n",
    "This code demonstrates how the agent interacts with its knowledge base to answer a specific query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"answer from the knowledge base, what is the color of sky?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from phi.agent import Agent, AgentKnowledge\n",
    "# from phi.vectordb.lancedb import LanceDb\n",
    "# from phi.vectordb.search import SearchType\n",
    "# from phi.embedder.fastembed import FastEmbedEmbedder\n",
    "\n",
    "# # Create knowledge base with recreate=True\n",
    "# knowledge_base = AgentKnowledge(\n",
    "#     vector_db=LanceDb(\n",
    "#         table_name=\"fastembed_documents\",\n",
    "#         uri=\"tmp/lancedb\",\n",
    "#         search_type=SearchType.vector,\n",
    "#         embedder=FastEmbedEmbedder(),\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Add data to the knowledge base\n",
    "# knowledge_base.load_text(\"The sky is green\")\n",
    "# # knowledge_base.load_text(\"Machine learning is a subset of artificial intelligence\")\n",
    "\n",
    "# # Load with recreate=True to rebuild the schema\n",
    "# # knowledge_base.load(recreate=True)  # This will recreate the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The code in the next cell performs the following actions:\n",
    "\n",
    "1. **Creating a Knowledge Base from a PDF**:\n",
    "    - The `PDFUrlKnowledgeBase` class is used to create a knowledge base from a PDF file.\n",
    "    - The PDF file is located at the URL `\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"`.\n",
    "\n",
    "2. **Configuring the Vector Database**:\n",
    "    - The knowledge base uses `LanceDb` as the vector database for storing and searching embeddings.\n",
    "    - The vector database is configured with:\n",
    "        - `table_name`: The name of the table in the database (`\"recipes\"`).\n",
    "        - `uri`: The location of the database (`\"tmp/lancedb\"`).\n",
    "        - `search_type`: The type of search to perform (`SearchType.vector`).\n",
    "        - `embedder`: The embedding model to use (`OpenAIEmbedder` with the model `\"text-embedding-3-small\"`).\n",
    "\n",
    "3. **Loading the Knowledge Base**:\n",
    "    - The `load()` method is called to load the PDF content into the knowledge base.\n",
    "    - This step is commented out after the first run to avoid reloading the data.\n",
    "\n",
    "4. **Creating an Agent**:\n",
    "    - An `Agent` object is created with the following configurations:\n",
    "        - `model`: The agent uses the `OpenAIChat` model with the ID `\"gpt-4o\"`.\n",
    "        - `knowledge`: The knowledge base created from the PDF is added to the agent.\n",
    "        - `show_tool_calls`: Enables displaying tool calls made by the agent.\n",
    "        - `markdown`: Enables markdown formatting for the agent's responses.\n",
    "        - `stream`: Enables streaming of the agent's responses.\n",
    "\n",
    "5. **Commented Example Query**:\n",
    "    - An example query (`\"How do I make chicken and galangal in coconut milk soup\"`) is provided but commented out.\n",
    "    - Uncommenting this line allows the agent to generate a response based on the knowledge base.\n",
    "\n",
    "This code demonstrates how to create a knowledge base from a PDF, configure it with a vector database, and use it with an intelligent agent to answer queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phi.knowledge.pdf import PDFUrlKnowledgeBase\n",
    "\n",
    "# Create a knowledge base from a PDF\n",
    "knowledge_base = PDFUrlKnowledgeBase(\n",
    "    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n",
    "    # Use LanceDB as the vector database\n",
    "    vector_db=LanceDb(\n",
    "        table_name=\"recipes\",\n",
    "        uri=\"tmp/lancedb\",\n",
    "        search_type=SearchType.vector,\n",
    "        # embedder=OpenAIEmbedder(model=\"text-embedding-3-small\"),\n",
    "        embedder=SentenceTransformerEmbedder(model=\"all-MiniLM-L6-v2\" ) \n",
    "    ),\n",
    ")\n",
    "# Comment out after first run as the knowledge base is loaded\n",
    "knowledge_base.load()\n",
    "\n",
    "agent = Agent(\n",
    "    model=OpenAIChat(id=\"gpt-4o\"),\n",
    "    # Add the knowledge base to the agent\n",
    "    knowledge=knowledge_base,\n",
    "    show_tool_calls=True,\n",
    "    markdown=True,  \n",
    "    stream=True\n",
    ")\n",
    "# agent.print_response(\"How do I make chicken and galangal in coconut milk soup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The code in the next cell performs the following actions:\n",
    "\n",
    "1. **Importing Modules**:\n",
    "    - `Markdown` and `display` from `IPython.display`: These are used to render and display Markdown content in the Jupyter Notebook.\n",
    "\n",
    "2. **Running the Agent**:\n",
    "    - The `run` method of the `agent` object is called with the input `\"How do I make chicken and galangal in coconut milk soup\"`.\n",
    "    - This prompts the agent to search its knowledge base and provide a response based on the stored information.\n",
    "\n",
    "3. **Displaying the Response**:\n",
    "    - The response from the agent is stored in the variable `response`.\n",
    "    - The `content` attribute of the `response` object is rendered as Markdown using the `Markdown` class.\n",
    "    - The `display` function is used to display the rendered Markdown content in the notebook.\n",
    "\n",
    "This code demonstrates how to query the agent and display its response in a readable Markdown format within the Jupyter Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "response=agent.run(\"How do I make chicken and galangal in coconut milk soup\")\n",
    "\n",
    "# print(response.content)\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The code in the next cell performs the following actions:\n",
    "\n",
    "1. **Importing Modules**:\n",
    "    - `CSVKnowledgeBase` from `phi.knowledge.csv`: Used to create a knowledge base from a CSV file.\n",
    "    - `ChromaDb` from `phi.vectordb.chroma`: Used to manage a vector database for storing and searching embeddings.\n",
    "\n",
    "2. **Creating a Knowledge Base**:\n",
    "    - A `CSVKnowledgeBase` object is created with the following configurations:\n",
    "        - `path`: Specifies the location of the CSV file (`\"wip\"`).\n",
    "        - `vector_db`: Configures the vector database using `ChromaDb` with the collection name `\"imdb_csv\"`.\n",
    "\n",
    "This setup initializes a knowledge base from a CSV file and configures it with a vector database for efficient storage and retrieval of embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phi.knowledge.csv import CSVKnowledgeBase\n",
    "from phi.vectordb.chroma import ChromaDb\n",
    "\n",
    "knowledge_base = CSVKnowledgeBase(path='.', vector_db=ChromaDb(collection=\"imdb_csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The code in the next cell performs the following actions:\n",
    "\n",
    "1. **Importing Modules**:\n",
    "    - `Agent` from `phi.agent`: Used to create an intelligent agent.\n",
    "\n",
    "2. **Creating an Agent**:\n",
    "    - An `Agent` object is created with the following configurations:\n",
    "        - `knowledge`: The knowledge base created from the CSV file is added to the agent.\n",
    "        - `search_knowledge`: Enables the agent to search the knowledge base when needed.\n",
    "\n",
    "3. **Loading the Knowledge Base**:\n",
    "    - The `load` method of the `knowledge` attribute of the agent is called with the parameter `recreate=False`.\n",
    "    - This ensures that the knowledge base is loaded without recreating it, preserving any existing data.\n",
    "\n",
    "This code demonstrates how to initialize an agent with a CSV-based knowledge base and prepare it for querying.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phi.agent import Agent\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    knowledge=knowledge_base,\n",
    "    search_knowledge=True,\n",
    ")\n",
    "\n",
    "agent.knowledge.load(recreate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The code in the next cell performs the following actions:\n",
    "\n",
    "1. **Querying the Agent**:\n",
    "    - The `run` method of the `agent` object is called with the input `\"List action movies\"`.\n",
    "    - This prompts the agent to search its knowledge base and provide a response based on the stored information.\n",
    "\n",
    "2. **Displaying the Response**:\n",
    "    - The response from the agent is stored in the variable `response`.\n",
    "    - The `content` attribute of the `response` object is rendered as Markdown using the `Markdown` class.\n",
    "    - The `display` function is used to display the rendered Markdown content in the notebook.\n",
    "\n",
    "This code demonstrates how to query the agent for a specific request and display its response in a readable Markdown format within the Jupyter Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=agent.run(\"List action movies\")\n",
    "\n",
    "display(Markdown(response.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phidata_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
