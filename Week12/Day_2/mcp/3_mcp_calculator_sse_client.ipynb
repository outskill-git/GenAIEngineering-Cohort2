{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MCP Calculator Client with Mistral AI (SSE Version)\n",
        "\n",
        "This notebook demonstrates how to use MCP (Model Context Protocol) with Mistral AI's chat completion API using Server-Sent Events (SSE) connection.\n",
        "\n",
        "## What is SSE?\n",
        "Server-Sent Events (SSE) is a technology that allows a server to push data to web clients over HTTP. In the context of MCP, it provides a way to connect to MCP servers through HTTP endpoints instead of STDIO."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before running this notebook, make sure you have:\n",
        "1. The required packages installed\n",
        "2. An MCP server running on `http://localhost:9321/sse`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# !pip install mcp mistralai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Libraries\n",
        "\n",
        "The SSE client allows us to connect to MCP servers over HTTP, which is useful for:\n",
        "- Remote server connections\n",
        "- Web-based integrations\n",
        "- Scenarios where STDIO is not suitable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è  Removing conflicting OPENAI_API_KEY\n",
            "‚ö†Ô∏è  Removing conflicting OPENAI_BASE_URL\n",
            "‚ö†Ô∏è  Removing conflicting OPENAI_API_BASE\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import json\n",
        "from mcp import ClientSession, StdioServerParameters\n",
        "from mcp.client.sse import sse_client\n",
        "from mcp.client.stdio import stdio_client\n",
        "# from mistralai import Mistral\n",
        "import openai\n",
        "import sys\n",
        "\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "env_vars_to_clear = ['OPENAI_API_KEY', 'OPENAI_BASE_URL', 'OPENAI_API_BASE']\n",
        "for var in env_vars_to_clear:\n",
        "    if os.getenv(var):\n",
        "        print(f\"‚ö†Ô∏è  Removing conflicting {var}\")\n",
        "        del os.environ[var]\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPEN_ROUTER_KEY\")\n",
        "os.environ['OPENAI_API_BASE'] = 'https://openrouter.ai/api/v1'\n",
        "os.environ['OPENAI_BASE_URL'] = 'https://openrouter.ai/api/v1'\n",
        "\n",
        "\n",
        "\n",
        "# env_vars_to_clear = ['OPENAI_API_KEY', 'OPENAI_BASE_URL', 'OPENAI_API_BASE']\n",
        "# for var in env_vars_to_clear:\n",
        "#     if os.getenv(var):\n",
        "#         print(f\"‚ö†Ô∏è  Removing conflicting {var}\")\n",
        "#         del os.environ[var]\n",
        "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPEN_AI_KEY\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure Mistral AI Client\n",
        "\n",
        "Set up your Mistral AI API key to enable LLM interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to MCP Server via SSE\n",
        "\n",
        "Unlike the STDIO version, here we connect to an HTTP endpoint. The server should be running and accessible at the specified URL.\n",
        "\n",
        "**Note**: Make sure your MCP server is running on port 9321 before executing this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üßÆ Calculator ready! Found 2 tools\n"
          ]
        }
      ],
      "source": [
        "# SSE server endpoint\n",
        "server_params = \"http://localhost:9321/sse\"\n",
        "\n",
        "# Connect using SSE client\n",
        "async with sse_client(server_params) as (read, write):\n",
        "    async with ClientSession(read, write) as session:\n",
        "        # Initialize the session\n",
        "        await session.initialize()\n",
        "        \n",
        "        # Discover available tools\n",
        "        tools_result = await session.list_tools()\n",
        "        print(f\"\\nüßÆ Calculator ready! Found {len(tools_result.tools)} tools\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transform Tools for Mistral AI\n",
        "\n",
        "Just like in the STDIO version, we need to convert the MCP tool format to match Mistral's expectations. The transformation process remains the same regardless of the connection type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "mcp_tools = []\n",
        "for tool in tools_result.tools:\n",
        "    tool_def = {\n",
        "        \"type\": \"function\",  # Required wrapper\n",
        "        \"function\": {        # Function definition\n",
        "            \"name\": tool.name,\n",
        "            \"description\": tool.description,\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"a\": {\n",
        "                        \"type\": \"number\",\n",
        "                        \"description\": \"First number\"\n",
        "                    },\n",
        "                    \"b\": {\n",
        "                        \"type\": \"number\",\n",
        "                        \"description\": \"Second number\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"a\", \"b\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    mcp_tools.append(tool_def)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display Available Tools\n",
        "\n",
        "Let's inspect the tools that were discovered and transformed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'function',\n",
              "  'function': {'name': 'add',\n",
              "   'description': 'Add two numbers together',\n",
              "   'parameters': {'type': 'object',\n",
              "    'properties': {'a': {'type': 'number', 'description': 'First number'},\n",
              "     'b': {'type': 'number', 'description': 'Second number'}},\n",
              "    'required': ['a', 'b']}}},\n",
              " {'type': 'function',\n",
              "  'function': {'name': 'subtract',\n",
              "   'description': 'Subtract b from a',\n",
              "   'parameters': {'type': 'object',\n",
              "    'properties': {'a': {'type': 'number', 'description': 'First number'},\n",
              "     'b': {'type': 'number', 'description': 'Second number'}},\n",
              "    'required': ['a', 'b']}}}]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the transformed tools\n",
        "mcp_tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Request Calculation from Mistral\n",
        "\n",
        "Send a calculation request to Mistral. The AI will analyze the request and select the appropriate tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_input = \"Find 5 minus 2\"\n",
        "\n",
        "# Request Mistral to perform the calculation\n",
        "response = openai.chat.completions.create(\n",
        "    model=\"openai/gpt-4o\",\n",
        "    messages=[{\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a calculator assistant. Use the add or subtract functions to help the user with calculations.\"\n",
        "    }, {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_input\n",
        "    }],\n",
        "    tools=mcp_tools,\n",
        "    tool_choice=\"auto\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect MCP's Response\n",
        "\n",
        "Let's examine what MCP returned, including the tool call details:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_L9RdekeJ8apFXDarIgEoOG1u', function=Function(arguments='{\"a\":5,\"b\":2}', name='subtract'), type='function', index=0)], reasoning=None)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the response message\n",
        "response.choices[0].message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute the Tool Call via SSE\n",
        "\n",
        "Now we'll execute the tool that Mistral selected. The main difference from STDIO is that we're connecting via HTTP/SSE instead of process pipes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result: 3.0\n"
          ]
        }
      ],
      "source": [
        "message = response.choices[0].message\n",
        "\n",
        "# Connect to SSE server to execute the tool\n",
        "async with sse_client(\"http://localhost:9321/sse\") as (read, write):\n",
        "    async with ClientSession(read, write) as session:\n",
        "        # Initialize session\n",
        "        await session.initialize()\n",
        "        \n",
        "        if message.tool_calls is not None:\n",
        "            for tool_call in message.tool_calls:\n",
        "                # Extract function name\n",
        "                func_name = tool_call.function.name\n",
        "                \n",
        "                # Parse arguments (handle both string and dict formats)\n",
        "                if isinstance(tool_call.function.arguments, str):\n",
        "                    args = json.loads(tool_call.function.arguments)\n",
        "                else:\n",
        "                    args = tool_call.function.arguments\n",
        "                \n",
        "                # Execute the MCP tool\n",
        "                result = await session.call_tool(func_name, args)\n",
        "                print(f\"Result: {result.content[0].text}\")\n",
        "        else:\n",
        "            print(\"No tool calls found in the response.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Comparison\n",
        "\n",
        "### SSE vs STDIO\n",
        "\n",
        "**SSE (This notebook):**\n",
        "- Connects via HTTP endpoint\n",
        "- Good for remote servers\n",
        "- Suitable for web integrations\n",
        "- Requires server to be running on a specific port\n",
        "\n",
        "**STDIO (Previous notebook):**\n",
        "- Connects via process pipes\n",
        "- Good for local servers\n",
        "- Better process isolation\n",
        "- Server runs as a subprocess\n",
        "\n",
        "Both approaches achieve the same result but are suited for different deployment scenarios."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "phidata_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
